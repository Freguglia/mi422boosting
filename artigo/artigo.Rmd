---
title: Boosting

blinded: 0

authors: 

- name: Victor Freguglia Souza
  affiliation: "RA: 137784"
  
- name: Leonardo Uchoa Pedreira
  affiliation: "RA: 156231"

keywords: 
- Quando for a versão final.
- Tirar esse campo na .tex;

abstract: |
  The text of your abstract.  200 or fewer words.

bibliography: bibliography.bib
header-includes:
- \usepackage[utf8]{inputenc}
- \usepackage[portuguese]{algorithm2e}
- \usepackage[portuguese]{babel}
- \usepackage{amssymb}
output: rticles::asa_article
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
# Possivelmente ajustar as figuras aqui direto.
```

```{r load_pkgs}
library(tidyverse)
library(caret)
library(doMC)
require(xgboost)
```

```{r load_mnist, cache = TRUE}
if (file.exists("mnist_train.csv")){
  MNIST <- read_csv("mnist_train.csv", col_names = FALSE)
} else if (file.exists("../mnist_train.csv")) {
  MNIST <- read_csv("../mnist_train.csv", col_names = FALSE)
} else {
  stop("Não achei o arquivo do arquivo :( Precisa colocar o arquivo que a gente usou pros labs 'mnist_train.csv' na pasta.")
}

names(MNIST)[1] <- "Y"
MNIST$Y <- as.factor(MNIST$Y)

set.seed(1)
idx_teste <- sample(1:nrow(MNIST), 55000, replace = FALSE)
treino <- MNIST[-idx_teste, ]
teste <- MNIST[idx_teste, ]

colvars <- apply(MNIST,2,var)
cols_in <- as.numeric(c(1,which(colvars > 10)))

```

```{r ajuste_gbm, include = FALSE, cache = TRUE, eval = FALSE}
registerDoMC(3)
set.seed(1)
tc <- trainControl(number = 1, repeats = 1)
xgb <- train(Y ~ ., data = treino[,cols_in], method = "xgbTree", trControl = tc, 
             tuneGrid = expand.grid(nrounds = c(600),
                                   max_depth = c(6),
                                   eta = c(.08),
                                   gamma = 0,
                                   colsample_bytree = 0.8,
                                   subsample = 0.8,
                                   min_child_weight = 1),
             nthread = 1)
mean(unlist(teste[,1]) == predict(xgb, teste[,cols_in]))
```


# Introdução

 Boosting é o nome dado a um tipo de algoritmo que, assim como outros métodos em Machine Learning como Bagging e Florestas Aleatórias, busca combinar um grande número de preditores com baixo poder de predição (isto é, um pouco mais eficientes do que a escolha ao acaso) para compor um bom preditor.  O conceito é fundamentado nas ideias apresentadas em @kearns1988 e @schapire1990.
 
 Diferentemente dos outros métodos citados, onde os preditores fracos que serão combinados são criados de maneira independente (e aleatória devido ao processo de bootstrap), no método de Boosting os preditores fracos são criados de maneira a melhorar o desempenho em regiões com altas taxas de erro. Isto é, se pensarmos que cada preditor tem um "voto" na decisão final, o método nos fornece um comitê em que aqueles que tem grande convicção têm mais poder na decisão. Estes de grande convicção, sabem muito sobre uma parte do espaço amostral (não sei se amostral é a melhor palavra).
 
O algoritmo AdaBoost (de \textit{Adaptative Boosting}), apresentado pela primeira vez em @adaboost, é um dos exemplos mais clássicos de algoritmo de boosting para o problema de classificação binária. Nele, a cada passo $m$, um novo classificador $G_m$ é ajustado com base em uma versão ponderada do conjunto de dados original, na qual o peso de cada observação depende do desempenho do classificador anterior: pontos classificados de maneira errada recebem peso maior, e assim, têm uma chance maior de serem corrigidos pelos classificadores ajustados na próxima iteração. O Algoritmo \ref{adaboost_alg} apresenta a descrição completa do AdaBoost. Note que os classificadores $G_m$ a serem usados não precisam ser de nenhum tipo específico e, portanto, se comporta como um parâmetro a ser escolhido por um processo de regulagem (tuning) do problema. Apesar disso, o mais comum, pela grande flexibilidade, é a árvore de classificação e regressão (CART).

\begin{algorithm}[h]
\Inicio{
  $(y_i, x_i), i = 1,\dots, N$; $y_i \in \{-1,1\}$; $x_i \in \mathbb{R}^p$;\\
  Inicie todos pesos $w_i = 1/N$;\\
  \Para{$m = 1,\dots,M$}{
    1. Ajuste um classificador $G_m(x)$;\\
    2. Calcular 
    
    $$\text{err}_m = \frac{\sum_{i = 1}^N w_i I(y_i \neq G_m(x_i))}{\sum_{i = 1}^N w_i};$$\\
    3. Calcular $\alpha_m = \log \left(\frac{1 - \text{err}_m}{\text{err}_m}\right)$;\\
    4. Atualizar $w_i \leftarrow w_i \exp \left( \alpha_m I(y_i \neq G_m(x_i)) \right), i = 1, \dots, N$;
  }
  Defina o classificador final como 
  $$G(x) = \text{sign}(\sum_{m = 1}^M \alpha_m I(G_m(x) = k)).$$
}
\caption{Algoritmo AdaBoost apresentado em \cite{elements}. Aqui, as classes do problema de classificação são representadas pelos valores -1 e 1.}
\label{adaboost_alg}
\end{algorithm}

Embora o AdaBoost seja um bom ponto de início para entender o conceito de Boosting, ele foi projetado para resolver problemas de classificação binária, e por isso, não apresenta resultados tão bons quando diretamente adaptado a problemas de classificação múltipla e regressão, então diferentes algoritmos são necessários para esses casos. @SAMME propõe uma modificação do AdaBoost para o caso de classificação múltipla, por exemplo.

A principal diferença entre os diferentes algoritmos de Boosting propostos está na maneira com que os a ponderação dos dados é feita em cada passo. Nesse trabalho, por apresentar uma forma mais geral, será considerado o algoritmo Gradient Boosting, que pode lidar com todos os tipos de problemas de predição com a devida escolha da função perda a ser minimizada. A teoria que o fundamenta e sua descrição detalhada são apresentadas na Seção \ref{sec_metodologia}. O método é então aplicado ao conjunto de dados MNIST, descrito na Seção \ref{sec_dados} e os resultados são mostrados na Seção \ref{sec_apli}.
  
# Metodologia \label{sec_metodologia}

Do ponto de vista da teoria de decisão, escolher o melhor preditor significa escolher a função $G^*$ que minimiza a função risco, definida como o valor esperado da função de perda $L(\cdot,\cdot)$.

\begin{equation}
G^* = \arg \min_{G \in \mathcal{G}} \mathbb{E}L(Y,G(\mathbf{X}))
\end{equation}

Em particular, em um procedimento de Boosting, estamos procurando em um espaço de funções $\mathcal{G}$ formado por combinações de preditores fracos $h_m$ de alguma forma pré-definida, por exemplo, árvores de decisão com um número fixo (e, em geral, pequeno) de nós,

\begin{equation}
\mathcal{G} = \{G: G(x) = \sum_{i = 1}^M \alpha_i h_m(x) \}.
\end{equation}

Note que, o risco para um preditor específico $G$ é desconhecido, uma vez que não assumimos nenhuma distribuição, impossibilitando o calculo do valor esperado da função perda para esse preditor. Uma boa estratégia para criação de uma função de predição $G \in \mathcal{G}$ consiste então em escolher iterativamente os preditores $h_m$ de forma a reduzir o risco (empírico) a cada passo. Um método muito comum para atingir pontos de mínimo em procedimentos iterativos é mover a solução na direção contrária ao gradiente em cada iteração (algoritmo de Newton-Raphson e Backpropagation são exemplos parecidos) e nisso é baseado o algoritmo chamado Gradient Boosting.
 
## Gradient Boosting

 - Citar o xgboost, caret.
 
 \begin{algorithm}[h]
\Inicio{
  $(y_i, x_i), i = 1,\dots, N$;\\
  Inicie com o preditor constante $H_0 = \arg \min_c \sum_{i = 1}^N L(y_i,c)$;\\
  \Para{$m = 1,\dots,M$}{
    1. Calcular
    $$r_{im} = -\left[ \frac{\partial L(y_i, G(x_i))}{\partial }\right]_{G = H_{m-1}};$$\\
    2. Ajustar um novo preditor fraco $h_m$ ao conjunto de dados $(r_{im},x_i);$\\
    3. ;\\
    4. ;
  }
  Defina o classificador final como 
  $$G(x) = H_M(x).$$
}
\caption{Algoritmo Gradient Boosting apresentado em \cite{boosting2001}.}
\label{gradboost_alg}
\end{algorithm}

## PCA Whitening

Talvez isso não seja necessário pois habitualmente as arvores nao precisam desse tipo de tratamento. Svm e redes habitualmente precisam pq usam demais combinacoes lineares. 

Mas essa secao pode ser util pra fazer comparacao com os outros metodos em que isso serve e melhorar a secao de discussao.

# Dados \label{sec_dados}

Conjunto de dados MNIST.

- Mostrar alguns números

# Aplicação \label{sec_apli}

- Ajuste
- Comparar com Random Forest, nnet, pca-whitened

# Discussão

- Não sei o que entra em discussão/conclusão?

Proposta:

Discutir (pq em aplicação não há discussão crítica) os resultados da comparação do gbm com os métodos anteriores em questão de velocidade, precisão, flexibilidade. Considerar as variantes xgboost, lightgbm

Discutir efeito do pca no gbm e em outros métodos que precisem disso, como redes e svm.

Usar outros aspectos considerados no arquivo "kuhn_cheatsheet" pra comparar?
  
# Conclusão

Fazer por último e ver o que aprendemos do trabalho.