---
title: Boosting

blinded: 0

authors: 

- name: Victor Freguglia Souza
  affiliation: "RA: 137784"
  
- name: Leonardo Uchoa Pedreira
  affiliation: "RA: 156231"

keywords: 
- Quando for a versão final.
- Tirar esse campo na .tex;

abstract: |
  The text of your abstract.  200 or fewer words.

bibliography: bibliography.bib
header-includes:
- \usepackage[utf8]{inputenc}
- \usepackage[portuguese]{algorithm2e}
- \usepackage[portuguese]{babel}
- \usepackage{amssymb}
output: rticles::asa_article
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo=FALSE, 
                      warning=FALSE, 
                      message=FALSE,
                      eval = FALSE, # soh para compilar o texto rapido
                      include = FALSE) 
# Possivelmente ajustar as figuras aqui direto.
```

```{r load_pkgs}
library(tidyverse)
library(caret)TRUE
library(doMC)
require(xgboost)
```

```{r load_mnist, cache = TRUE}
if (file.exists("mnist_train.csv")){
  MNIST <- read_csv("mnist_train.csv", col_names = FALSE)
} else if (file.exists("../mnist_train.csv.zip")) {
  MNIST <- read_csv("../mnist_train.csv.zip", col_names = FALSE)
} else {
  stop("Não achei o arquivo do arquivo :( Precisa colocar o arquivo que a gente usou pros labs 'mnist_train.csv' na pasta.")
}

names(MNIST)[1] <- "Y"
MNIST$Y <- as.factor(MNIST$Y)

set.seed(1)
idx_teste <- sample(1:nrow(MNIST), 55000, replace = FALSE)
treino <- MNIST[-idx_teste, ]
teste <- MNIST[idx_teste, ]

colvars <- apply(MNIST,2,var)
cols_in <- as.numeric(c(1,which(colvars > 10)))

```

```{r ajuste_gbm, cache = TRUE, eval = FALSE}
registerDoMC(3)
set.seed(1)
tc <- trainControl(number = 1, repeats = 1)
xgb <- train(Y ~ ., data = treino[,cols_in], method = "xgbTree", trControl = tc, 
             tuneGrid = expand.grid(nrounds = c(600),
                                   max_depth = c(6),
                                   eta = c(.08),
                                   gamma = 0,
                                   colsample_bytree = 0.8,
                                   subsample = 0.8,
                                   min_child_weight = 1),
             nthread = 1)
mean(unlist(teste[,1]) == predict(xgb, teste[,cols_in]))
```


# Introdução

 Boosting é o nome dado a um tipo de algoritmo que, assim como outros métodos em Machine Learning como Bagging e Florestas Aleatórias, busca combinar um grande número de preditores com baixo poder de predição (isto é, um pouco mais eficientes do que a escolha ao acaso) para compor um bom preditor.  O conceito é fundamentado nas ideias apresentadas em @kearns1988 e @schapire1990.
 
 Diferentemente dos outros métodos citados, onde os preditores fracos que serão combinados são criados de maneira independente (e aleatória devido ao processo de bootstrap), no método de Boosting os preditores fracos são criados de maneira a melhorar o desempenho em regiões com altas taxas de erro. Isto é, se pensarmos que cada preditor tem um "voto" na decisão final, o método nos fornece um comitê em que aqueles que tem grande convicção têm mais poder na decisão. Estes de grande convicção, sabem muito sobre uma parte do espaço amostral (não sei se amostral é a melhor palavra).
 
O algoritmo AdaBoost (de \textit{Adaptative Boosting}), apresentado pela primeira vez em @adaboost, é um dos exemplos mais clássicos de algoritmo de boosting para o problema de classificação binária. Nele, a cada passo $m$, um novo classificador $G_m$ é ajustado com base em uma versão ponderada do conjunto de dados original, na qual o peso de cada observação depende do desempenho do classificador anterior: pontos classificados de maneira errada recebem peso maior, e assim, têm uma chance maior de serem corrigidos pelos classificadores ajustados na próxima iteração. O Algoritmo \ref{adaboost_alg} apresenta a descrição completa do AdaBoost. Note que os classificadores $G_m$ a serem usados não precisam ser de nenhum tipo específico e, portanto, se comporta como um parâmetro a ser escolhido por um processo de regulagem (tuning) do problema. Apesar disso, o mais comum, pela grande flexibilidade, é a árvore de classificação e regressão (CART).

\begin{algorithm}[h]
\Inicio{
  $(y_i, x_i), i = 1,\dots, N$; $y_i \in \{-1,1\}$; $x_i \in \mathbb{R}^p$;\\
  Inicie todos pesos $w_i = 1/N$;\\
  \Para{$m = 1,\dots,M$}{
    1. Ajuste um classificador $G_m(x)$;\\
    2. Calcular 
    
    $$\text{err}_m = \frac{\sum_{i = 1}^N w_i I(y_i \neq G_m(x_i))}{\sum_{i = 1}^N w_i};$$\\
    3. Calcular $\alpha_m = \log \left(\frac{1 - \text{err}_m}{\text{err}_m}\right)$;\\
    4. Atualizar $w_i \leftarrow w_i \exp \left( \alpha_m I(y_i \neq G_m(x_i)) \right), i = 1, \dots, N$;
  }
  Defina o classificador final como 
  $$G(x) = \text{sign}(\sum_{m = 1}^M \alpha_m I(G_m(x) = k)).$$
}
\caption{Algoritmo AdaBoost apresentado em \cite{elements}. Aqui, as classes do problema de classificação são representadas pelos valores -1 e 1.}
\label{adaboost_alg}
\end{algorithm}

Embora o AdaBoost seja um bom ponto de início para entender o conceito de Boosting, ele foi projetado para resolver problemas de classificação binária, e por isso, não apresenta resultados tão bons quando diretamente adaptado a problemas de classificação múltipla e regressão, então diferentes algoritmos são necessários para esses casos. @SAMME propõe uma modificação do AdaBoost para o caso de classificação múltipla, por exemplo.

A principal diferença entre os diferentes algoritmos de Boosting propostos está na maneira com que os a ponderação dos dados é feita em cada passo. Nesse trabalho, por apresentar uma forma mais geral, será considerado o algoritmo Gradient Boosting, que pode lidar com todos os tipos de problemas de predição com a devida escolha da função perda a ser minimizada. A teoria que o fundamenta e sua descrição detalhada são apresentadas na Seção \ref{sec_metodologia}. O método é então aplicado ao conjunto de dados MNIST, descrito na Seção \ref{sec_dados} e os resultados são mostrados na Seção \ref{sec_apli}.
  
# Metodologia \label{sec_metodologia}

Em problemas de regressão, escolher o melhor preditor significa estimar uma função $f^*$ que minimiza o risco, definido como o valor esperado da função de perda $L(\cdot,\cdot)$, ou seja,

\begin{equation}
f^* = \arg \min_{f \in \mathcal{F}} \mathbb{E}_{Y|x} \big[ L(Y,f(x)) | x \big ].
\label{eq:general_argmin}
\end{equation}

Note que o risco para um preditor específico $f$ é desconhecido, uma vez que não assumimos nenhuma distribuição, o que impossibilita o cálculo do valor esperado da função perda para esse preditor. Uma boa estratégia para criação da função de predição $f \in \mathcal{F}$ consiste em escolher preditores de forma a minimizar o risco empírico.

\begin{equation}
\begin{aligned}
& f^* = \arg \min_{f \in \mathcal{F}} \sum_{i=1}^N  L(y_i,f(x_i)) \\
& \text{sujeito à que f seja árvore}
\end{aligned}
\label{eq:emp_general_argmin}
\end{equation}

Uma forma de resolver o problema \ref{eq:emp_general_argmin} é via utilização de algorítmos numéricos. Gradiente descendente (citar watkins), por exemplo, é uma estratégia habitualmente utilizada, que levaria ao algorítmo

\begin{equation}
f^{(i+1)} = f^{(i)} + \sum_{i=1}^N \nabla_f L(y_i,f(x_i))
\end{equation}

Entretanto (@boosting2001) cita que simplesmente utilizar isto teria efeitos catastróficos no modelo preditivo. Primeiro porquê só são levados em consideração as observações que temos (i.e, não existe nenhuma intenção de extrapolar poder preditivo, como por exemplo a separação entre teste e treinamento ou validação cruzada faria), segundo que não é levado em consideração à relação entre as covariáveis. Para contornar este problema, o autor sugere utilizar árvores de decisão de uma forma muito inteligente.

 Desta forma Boosting busca resolver o problema de otimização \ref{eq:general_argmin} sujeito à restrição de que $f^*$ sejam árvores de decisão (i.e, $\mathcal{F}$ é o conjunto de todas as possíveis árvores). Formalmente, uma árvore de decisão pode ser escrita como 

 
## Gradient Boosting

 - Citar o xgboost, caret.
 
 \begin{algorithm}[h]
\Inicio{
  $(y_i, x_i), i = 1,\dots, N$;\\
  Inicie com o preditor constante $H_0 = \arg \min_c \sum_{i = 1}^N L(y_i,c)$;\\
  \Para{$m = 1,\dots,M$}{
    1. Calcular
    $$r_{im} = -\left[ \frac{\partial L(y_i, G(x_i))}{\partial }\right]_{G = H_{m-1}};$$\\
    2. Ajustar um novo preditor fraco $h_m$ ao conjunto de dados $(r_{im},x_i);$\\
    3. ;\\
    4. ;
  }
  Defina o classificador final como 
  $$G(x) = H_M(x).$$
}
\caption{Algoritmo Gradient Boosting apresentado em \cite{boosting2001}.}
\label{gradboost_alg}
\end{algorithm}

## PCA Whitening

Talvez isso não seja necessário pois habitualmente as arvores nao precisam desse tipo de tratamento. Svm e redes habitualmente precisam pq usam demais combinacoes lineares. 

Mas essa secao pode ser util pra fazer comparacao com os outros metodos em que isso serve e melhorar a secao de discussao.

# Dados \label{sec_dados}

Conjunto de dados MNIST.

- Mostrar alguns números

# Aplicação \label{sec_apli}

- Ajuste
- Comparar com Random Forest, nnet, pca-whitened

# Discussão

- Não sei o que entra em discussão/conclusão?

Proposta:

Discutir (pq em aplicação não há discussão crítica) os resultados da comparação do gbm com os métodos anteriores em questão de velocidade, precisão, flexibilidade. Considerar as variantes xgboost, lightgbm

Discutir efeito do pca no gbm e em outros métodos que precisem disso, como redes e svm.

Usar outros aspectos considerados no arquivo "kuhn_cheatsheet" pra comparar?
  
# Conclusão

Fazer por último e ver o que aprendemos do trabalho.